{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "<h1><center> TSKS35: Information and Communications Engineering </center></h1>\n",
    "<br>\n",
    "<h2><center><font size=\"5\">Laboratory Exercise 3: Source coding</font></center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this laboratory exercise, we will explore the concepts of souce coding. We will focus on Huffman coding. Huffman codes are uniquely decodable instantaneous codes with minimum-average code word length. In this sense they are optimal. By optimality we  mean that, among all codes that satisfy the prefix condition (and therefore are uniquely  decodable and instantaneous), Huffman codes have the minimum-average code word  length. \n",
    "\n",
    "__NOTE:__  Read section 6.3 of the book for details of Huffman code, before the lab session.\n",
    "\n",
    "The excercise is divided into three steps: randomly generating the alphabet to be encoded, Huffman encoding, and decoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Generation of a random alphabet\n",
    "\n",
    "The following example demonstrates how to generate an alphabet containing four symbols and their corresponding probabilities. Learn more about generation of random numbers [here](https://docs.python.org/3/library/random.html) and the priority queue algorithm [here](https://docs.python.org/3/library/heapq.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0.40973778922431336, 'b': 0.36202295361507275, 'c': 0.0874319360662984, 'd': 0.14080732109431554}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from heapq import heappush, heappop, heapify\n",
    "from collections import defaultdict\n",
    "\n",
    "letters = [chr(i) for i in range(ord('a'), ord('p')+1)]\n",
    "random_probs = [random.random() for _ in range(4)]\n",
    "total_prob = sum(random_probs)\n",
    "probabilities = {letters[i]: random_probs[i] / total_prob for i in range(4)}\n",
    "\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "<font size=\"5\"><span style=\"color:green\"> Student task 1: Alphabet generation</span></font>\n",
    "\n",
    "Modify the example above to create an alphabet containing 16 symbols, with each symbol encoded using at most 8 bits for Huffman coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0.09336855997021744, 'b': 0.04921902933185552, 'c': 0.07923838396940176, 'd': 0.06802357875504669, 'e': 0.014440713162153276, 'f': 0.025617434824255117, 'g': 0.011350689053105755, 'h': 0.04095982365829953, 'i': 0.0749238142970325, 'j': 0.05363939981804183, 'k': 0.10221020619522098, 'l': 0.09448958596371265, 'm': 0.09060387723135677, 'n': 0.0737696470935717, 'o': 0.05563292724025158, 'p': 0.07251232943647687}\n",
      "Entropy of the source = 3.8348246572986167\n"
     ]
    }
   ],
   "source": [
    "# Write you code here ...\n",
    "import random\n",
    "from heapq import heappush, heappop, heapify\n",
    "from collections import defaultdict\n",
    "\n",
    "letters = [chr(i) for i in range(ord('a'), ord('p')+1)]\n",
    "random_probs = [random.random() for _ in range(16)]\n",
    "total_prob = sum(random_probs)\n",
    "probabilities = {letters[i]: random_probs[i] / total_prob for i in range(16)}\n",
    "\n",
    "print(probabilities)\n",
    "\n",
    "\n",
    "# Calculate the Entropy of the source\n",
    "import numpy as np\n",
    "prob_values = list(probabilities.values())\n",
    "# print(prob_values)\n",
    "res_list = []\n",
    "for i in range(0, len(prob_values)):\n",
    "    res_list.append(prob_values[i] * np.log2(prob_values[i]))\n",
    "\n",
    "# print(res_list)\n",
    "print(f\"Entropy of the source = {-sum(res_list)}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Huffman encoding\n",
    "\n",
    "The incomplete code snippet below performs the Huffman encoding operation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "<font size=\"5\"><span style=\"color:green\"> Student task 2: Huffman encoding</span></font>\n",
    "\n",
    "    \n",
    "Complete the code according to the instructions (in comments) so that it can fully perform Huffman encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0.09336855997021744, 'b': 0.04921902933185552, 'c': 0.07923838396940176, 'd': 0.06802357875504669, 'e': 0.014440713162153276, 'f': 0.025617434824255117, 'g': 0.011350689053105755, 'h': 0.04095982365829953, 'i': 0.0749238142970325, 'j': 0.05363939981804183, 'k': 0.10221020619522098, 'l': 0.09448958596371265, 'm': 0.09060387723135677, 'n': 0.0737696470935717, 'o': 0.05563292724025158, 'p': 0.07251232943647687}\n",
      "a: 000\n",
      "k: 010\n",
      "l: 001\n",
      "c: 1101\n",
      "d: 1001\n",
      "i: 1100\n",
      "j: 0111\n",
      "m: 1111\n",
      "n: 1011\n",
      "o: 1000\n",
      "p: 1010\n",
      "b: 11101\n",
      "f: 01100\n",
      "h: 11100\n",
      "e: 011011\n",
      "g: 011010\n",
      "Average length of Huffman codes = 4.25 bits/symbol\n"
     ]
    }
   ],
   "source": [
    "def huffman_coding(probabilities):\n",
    "    # # Create a heap where each element is a list containing probability, symbol, and current encoding\n",
    "    heap = [[weight, [symbol, \"\"]] for symbol, weight in probabilities.items()]\n",
    "    heapify(heap)  # Convert the list into a min-heap structure\n",
    "    # print(heap)\n",
    "\n",
    "    # Execute the loop while there are more than one element in the heap\n",
    "    while len(heap) > 1:\n",
    "\n",
    "        # print(heap)\n",
    "        \n",
    "        ## Start your code here:\n",
    "        # About 1 line of code: Pop the element with the smallest probability from the heap\n",
    "        lo = heappop(heap)\n",
    "        # About 1 line of code: Pop the element with the next smallest probability\n",
    "        hi = heappop(heap)\n",
    "\n",
    "        # Add '0' and '1' to the code prefix for the elements with the smallest and next smallest probability\n",
    "        # About 4 lines, using for loop\n",
    "        # lo[1][1] += '0'\n",
    "        # hi[1][1] += '1'\n",
    "        for codePrefix in lo[1:]:\n",
    "            codePrefix[1] = '0' + codePrefix[1]\n",
    "\n",
    "        # print(lo)\n",
    "        for codePrefix in hi[1:]:\n",
    "            codePrefix[1] = '1' + codePrefix[1]\n",
    "        \n",
    "        # Merge these two elements and push them back into the heap, combining their probabilities\n",
    "        heappush(heap, [lo[0] + hi[0]] + lo[1:] + hi[1:])\n",
    "        ## End your code here\n",
    "\n",
    "        # print()\n",
    "        # for _ in heap:\n",
    "        #     print(_)\n",
    "\n",
    "\n",
    "    \n",
    "    # Pop the final element from the heap and get the final list of codes\n",
    "    return sorted(heappop(heap)[1:], key=lambda p: (len(p[1]), p))\n",
    "\n",
    "# Generate Huffman codes based on the probability distribution\n",
    "# !! You need to use the probabilities generated in step 1 !!\n",
    "codes = huffman_coding(probabilities)\n",
    "# Convert the list to a dictionary for easy lookup\n",
    "code_dict = {item[0]: item[1] for item in codes}\n",
    "\n",
    "len_of_code = 0\n",
    "print(probabilities)\n",
    "# Print each letter along with its corresponding Huffman code\n",
    "for letter, code in code_dict.items():\n",
    "    print(f\"{letter}: {code}\")\n",
    "    len_of_code += len(code)\n",
    "\n",
    "# Average length of Huffman codes\n",
    "# THIS IS WRONG SHOULD BE THE AVERAGE LENGTH FROM THE PROBABILITY\n",
    "print(f\"Average length of Huffman codes = {len_of_code / len(code_dict)} bits/symbol\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Decoding\n",
    "\n",
    "The incomplete code below performs the Huffman decoding operation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "<font size=\"5\"><span style=\"color:green\"> Student task 3: Decoding operation</span></font>\n",
    "\n",
    "Please complete the code according to the instructions (in comments) so that it can fully perform Huffman decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded symbols: [['k'], ['e'], ['d'], ['d'], ['m'], ['c'], ['h']]\n"
     ]
    }
   ],
   "source": [
    "# Define the Huffman decoding function\n",
    "def huffman_decoding(encoded_string, codes):\n",
    "    # Create a mapping from codes to symbols by reversing the codes dictionary\n",
    "\n",
    "    ## Start your code here (about 2 lines)\n",
    "    reverse_codes = {v: k for k, v in codes.items()}\n",
    "    # Initialize a variable to accumulate bits into valid Huffman codes\n",
    "    accumulatedCodeBits = ''\n",
    "    # Initialize a list to hold the decoded symbols\n",
    "    decoded_output = []\n",
    "    ## End your code here\n",
    "\n",
    "    ## Start your code here (about 4 lines)\n",
    "    # Iterate over each bit in the encoded string\n",
    "    # print(codes)\n",
    "    for bit in encoded_string:\n",
    "        # Add the current bit to the accumulating code string\n",
    "        accumulatedCodeBits += bit\n",
    "        # Check if the accumulated string matches a code in the dictionary\n",
    "        correspondingSymbol = [k for k, v in codes.items() if v == accumulatedCodeBits]\n",
    "        # If a match is found, append the corresponding symbol to the output list\n",
    "        # Reset the accumulating string to start decoding the next set of bits\n",
    "        # print(accumulatedCodeBits)\n",
    "        if correspondingSymbol:\n",
    "            decoded_output.append(correspondingSymbol)\n",
    "            accumulatedCodeBits = ''\n",
    "    ## End your code here\n",
    "\n",
    "    return decoded_output  # Return the list of decoded symbols\n",
    "\n",
    "# Suppose we have an encoded string obtained from the Huffman coding process\n",
    "encoded_string = \"01001101110011001111111011110000\"\n",
    "\n",
    "# !! Suppose codes is the Huffman code dictionary previously generated !!\n",
    "# In practice, the decoder must know the encoding map, typically predefined or transmitted before the encoded data\n",
    "\n",
    "# Call the decoding function\n",
    "decoded_symbols = huffman_decoding(encoded_string, code_dict)\n",
    "\n",
    "# Print the decoded result\n",
    "print(\"Decoded symbols:\", decoded_symbols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please give your observations and discuss the results here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "<h2><center> Report of Laboratory Excercise 3 </center></h2>\n",
    "<br>\n",
    "\n",
    "Answer the following questions supporting your claims with formulations and results obtained from the Student Tasks. Add your codes at the end of the final report as appendix.\n",
    "    \n",
    "__NOTE:__ You should prepare these questions up to the next laboratory session. Teaching assistants will verify your progress during next session. Final report should be uploaded to Lisam in pdf format according to laboratory guidelines. \n",
    "    \n",
    "1. What is the difference between lossless and lossy compression? What type of compression is done with Huffman coding? (1 pt)\n",
    "2. Why Huffman source code is called fixed to variable-length coding? (1pt)\n",
    "3. What is the prefix condition? (1 pt)\n",
    "4. Why Huffman codes are said to be instantaneous? (1pt)\n",
    "5. Calculate the entropy of the source in Student task 1 and the average length of the corresponding Huffman code in Student task 2. Comment on your results and relate it to the source-coding theorem. (1 pt)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "A lossless compression keeps all the information is restored when uncompressed. A lossy compression removes some information that may be unnecessary but can not be restored. Huffman coding is lossless.\n",
    "\n",
    "## 2\n",
    "The Huffman process compresses the fixed length data by mapping each symbol to a variable-length code table. \n",
    "\n",
    "## 3\n",
    "The prefix condition means that the code can only be decoded in one way. There is no need to have separator for every symbol because the code sequence has no repeats, if 000 is used 000x is never used.\n",
    "\n",
    "## 4\n",
    "Because Huffman codes are prefix-free the code can be decoded as soon as the corresponding symbol is read. No need to check any more code when a symbol has been identified.\n",
    "\n",
    "## 5\n",
    "The entropy of the source in Student task 1 is around 3.74 of the random values generated. The average length of the corresponding Huffman code is around 4.44 for the random values generated. The source-coding theorem states that the entropy is the lowest average number of bits required to encode without loss. So as the length of the Huffman code is larger then the entropy it conforms to the source-coding theorem.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
